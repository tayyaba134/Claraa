{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import soundfile as sf\n",
    "from torchmetrics import MetricCollection, Recall, Accuracy, Precision, AveragePrecision\n",
    "\n",
    "from clara import PLCLARA\n",
    "from datautils import get_log_melspec\n",
    "from evutil import get_dataset\n",
    "from test_zeroshot import run as zeroshot_run\n",
    "#from test_zeroshot import zeroshot_classifier\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sr = sf.read('clara/demo/hello_world.mp3')\n",
    "mels = get_log_melspec(waveform, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = ['hello world', '10 am', 'tuesday', 'goodbye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(mels\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mels' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(mels.T.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_path', type=str, help='Path to model')\n",
    "parser.add_argument('--task', type=str, choices=['texts', 'gender', 'emotion', 'age', 'sounds', 'speech'], help='Task to run')\n",
    "parser.add_argument('--dataset_name', type=str, required=True, help='if task is sounds or emotion, specify dataset name')\n",
    "parser.add_argument('--root_cfg_path', type=str, default='./config/', help='root path to config files')\n",
    "parser.add_argument('--top_k', type=int, default=[1,5,10], help='Top k metrics to use')\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='Dataloader batch size')\n",
    "parser.add_argument('--num_workers', type=int, default=12, help='Dataloader number of workers')\n",
    "\n",
    "args = parser.parse_args(\n",
    "    '--model_path /fsx/knoriy/CLASP/logs/CLASP/Emotion_datasets_76acc_42epoch_60M/checkpoints/epoch=41-step=3402.ckpt --task emotion --dataset_name emov-db --root_cfg_path ../config/'.split()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:/fsx/knoriy/CLASP/logs/CLASP/Emotion_datasets_76acc_42epoch_60M/checkpoints/epoch=41-step=3402.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m PLCLARA\u001b[38;5;241m.\u001b[39mload_from_checkpoint(args\u001b[38;5;241m.\u001b[39mmodel_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1552\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1478\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1479\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1550\u001b[0m \n\u001b[0;32m   1551\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1552\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m _load_from_checkpoint(\n\u001b[0;32m   1553\u001b[0m         \u001b[38;5;28mcls\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1554\u001b[0m         checkpoint_path,\n\u001b[0;32m   1555\u001b[0m         map_location,\n\u001b[0;32m   1556\u001b[0m         hparams_file,\n\u001b[0;32m   1557\u001b[0m         strict,\n\u001b[0;32m   1558\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1559\u001b[0m     )\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\core\\saving.py:61\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m map_location \u001b[38;5;241m=\u001b[39m map_location \u001b[38;5;129;01mor\u001b[39;00m _default_map_location\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[1;32m---> 61\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[0;32m     64\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[0;32m     65\u001b[0m     checkpoint, checkpoint_path\u001b[38;5;241m=\u001b[39m(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     66\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:54\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(path_or_url, map_location)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[0;32m     51\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mopen(path_or_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(f, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\fsspec\\spec.py:1307\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1306\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[1;32m-> 1307\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(\n\u001b[0;32m   1308\u001b[0m         path,\n\u001b[0;32m   1309\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   1310\u001b[0m         block_size\u001b[38;5;241m=\u001b[39mblock_size,\n\u001b[0;32m   1311\u001b[0m         autocommit\u001b[38;5;241m=\u001b[39mac,\n\u001b[0;32m   1312\u001b[0m         cache_options\u001b[38;5;241m=\u001b[39mcache_options,\n\u001b[0;32m   1313\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1314\u001b[0m     )\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\fsspec\\implementations\\local.py:180\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[1;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\fsspec\\implementations\\local.py:302\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open()\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\fsspec\\implementations\\local.py:307\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m--> 307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[0;32m    309\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:/fsx/knoriy/CLASP/logs/CLASP/Emotion_datasets_76acc_42epoch_60M/checkpoints/epoch=41-step=3402.ckpt'"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# Model\n",
    "##############\n",
    "model = PLCLARA.load_from_checkpoint(args.model_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# DataModule\n",
    "##############\n",
    "\n",
    "dataset, templates, classes = get_dataset(\n",
    "    task = args.task, \n",
    "    dataset_name = args.dataset_name, \n",
    "    root_cfg_path = args.root_cfg_path, \n",
    "    batch_size = args.batch_size, \n",
    "    num_workers = args.num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(templates, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Metric\n",
    "##############\n",
    "num_classes = len(classes)\n",
    "metric = MetricCollection({})\n",
    "\n",
    "for top_k in args.top_k:\n",
    "    if top_k > num_classes:\n",
    "        break\n",
    "    metric.add_metrics({\n",
    "        f\"acc@{top_k}\":Accuracy(task='multiclass', num_classes=num_classes, top_k=top_k),\n",
    "        })\n",
    "\n",
    "##############\n",
    "# Run\n",
    "##############\n",
    "dataset.setup()\n",
    "\n",
    "zeroshot_weights, all_texts = zeroshot_classifier(model, classes, templates)\n",
    "tops = zeroshot_run(model, zeroshot_weights, dataset.test_dataloader(), metric, args.task, limit_batches=1)\n",
    "tops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchmetrics import MetricCollection, Recall, Accuracy, Precision, AveragePrecision\n",
    "\n",
    "from clasp import PLCLASP\n",
    "from text.tokeniser import Tokeniser\n",
    "from utils import calculate_average\n",
    "from evutil import get_dataset\n",
    "\n",
    "##############\n",
    "# Non Critical imports\n",
    "##############\n",
    "from pprint import pprint\n",
    "\n",
    "def run(model, zeroshot_weights, dataloader, metric_fn:MetricCollection, task:str, limit_batches=-1):\n",
    "\tdevice = model.device\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tmetrics = []\n",
    "\n",
    "\t\tmetric_fn = metric_fn.to(device)\n",
    "\n",
    "\t\tfor i, batch in enumerate(tqdm.tqdm(dataloader, desc='MiniBatch')):\n",
    "\t\t\tlabels, mels, _, _ = batch\n",
    "\t\t\tlabels = labels['texts'].to(device)\n",
    "\t\t\tmels = mels.to(device)\n",
    "\n",
    "\t\t\t###############\n",
    "\t\t\t# Get Temps\n",
    "\t\t\t###############\n",
    "\t\t\ttext_temp, audio_temp = model.get_temps()\n",
    "\n",
    "\t\t\t###############\n",
    "\t\t\t# Audio Features\n",
    "\t\t\t###############\n",
    "\t\t\taudio_features = model.encode_audio(mels)\n",
    "\t\t\taudio_features = model.model.audio_transform(audio_features)\n",
    "\t\t\taudio_features = F.normalize(audio_features, dim=-1)\n",
    "\n",
    "\t\t\t###############\n",
    "\t\t\t# Text Features\n",
    "\t\t\t###############\n",
    "\t\t\ttext_features = model.encode_text(labels)\n",
    "\t\t\ttext_features = model.model.text_transform(text_features)\n",
    "\t\t\ttext_features = F.normalize(text_features, dim=-1)\n",
    "\n",
    "\t\t\tlogits_per_audio = (audio_temp * (audio_features @ text_features.T))\n",
    "\t\t\tlabels = torch.eye(logits_per_audio.size(0)).to(device)\n",
    "\n",
    "\t\t# \t###############\n",
    "\t\t# \t# Get metrics\n",
    "\t\t# \t###############\n",
    "\t\t\tmetric = metric_fn(logits_per_audio, labels)\n",
    "\t\t\tmetrics.append(metric)\n",
    "\t\t\tif i == limit_batches:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tavg_metric = calculate_average(metrics)\n",
    "\n",
    "\treturn avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\t##############\n",
    "\t# Model\n",
    "\t##############\n",
    "\tmodel = PLCLASP.load_from_checkpoint(args.model_path).to(device)\n",
    "\n",
    "\t##############\n",
    "\t# DataModule\n",
    "\t##############\n",
    "\n",
    "\tdataset, templates, classes = get_dataset(\n",
    "\t\ttask = args.task, \n",
    "\t\tdataset_name = args.dataset_name, \n",
    "\t\troot_cfg_path = args.root_cfg_path, \n",
    "\t\tbatch_size = args.batch_size, \n",
    "\t\tnum_workers = args.num_workers\n",
    "\t)\n",
    "\n",
    "\t##############\n",
    "\t# Metric\n",
    "\t##############\n",
    "\t# num_classes = len(classes)\n",
    "\tmetric = MetricCollection({})\n",
    "\n",
    "\t# for top_k in args.top_k:\n",
    "\t# \tif top_k > num_classes:\n",
    "\t# \t\tbreak\n",
    "\t# \tmetric.add_metrics({\n",
    "\t# \t\tf\"rec@{top_k}\":Recall(task='multiclass', num_classes=num_classes, top_k=top_k),\n",
    "\t# \t\tf\"acc@{top_k}\":Accuracy(task='multiclass', num_classes=num_classes, top_k=top_k),\n",
    "\t# \t\tf\"pre@{top_k}\":Precision(task='multiclass', num_classes=num_classes, top_k=top_k),\n",
    "\t# \t\t})\n",
    "\n",
    "\t# metric.add_metrics({f\"AP\":AveragePrecision(task='multiclass', num_classes=num_classes)})\n",
    "\n",
    "\tmetric.add_metrics({f\"acc@{1}\":Accuracy(task='binary')})\n",
    "\n",
    "\t##############\n",
    "\t# Run\n",
    "\t##############\n",
    "\tdataset.setup()\n",
    "\n",
    "\tzeroshot_weights, all_texts = zeroshot_classifier(model, classes, templates)\n",
    "\ttops = run(model, zeroshot_weights, dataset.test_dataloader(), metric, args.task)\n",
    "\n",
    "\treturn tops\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\timport argparse\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\tparser.add_argument('--model_path', type=str, help='Path to model')\n",
    "\tparser.add_argument('--task', type=str, choices=['texts', 'gender', 'emotion', 'age', 'sounds', 'speech'], help='Task to run')\n",
    "\tparser.add_argument('--dataset_name', type=str, required=True, help='if task is sounds or emotion, specify dataset name')\n",
    "\tparser.add_argument('--root_cfg_path', type=str, default='./config/', help='root path to config files')\n",
    "\tparser.add_argument('--top_k', type=int, default=[1,5,10], help='Top k metrics to use')\n",
    "\tparser.add_argument('--batch_size', type=int, default=8, help='Dataloader batch size')\n",
    "\tparser.add_argument('--num_workers', type=int, default=12, help='Dataloader number of workers')\n",
    "\n",
    "\targs = parser.parse_args(\n",
    "        '--model_path ../logs/CLASP/US8K_77acc_57epoch_100M/checkpoints/epoch=57-step=15196.ckpt --task sounds --dataset_name us8k --root_cfg_path ../config/'.split()\n",
    "    )\n",
    "\n",
    "\ttops = main(args)\n",
    "\n",
    "\tpprint(tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fn = Accuracy(task='binary').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fn(*tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clasp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
